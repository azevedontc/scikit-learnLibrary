# -*- coding: utf-8 -*-
"""scikit-learnLibrary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wLmWwOaPhSBJKvUkNTwN0bLJW4-XQzVr

# Importações e Preparação do Dataset
"""

# Importações necessárias
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB, CategoricalNB
from sklearn.linear_model import LinearRegression, Perceptron
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# Carregar o dataset
df = pd.read_csv("Covid Data.csv")

# Usei para não errar o nome das colunas no pré-processamento
print(df.columns)

"""# Pré-processamento"""

# Pré-processamento inicial comum
df.replace({97: None, 99: None, '9999-99-99': None}, inplace=True) # Substituir valores específicos por NaN
imputer = SimpleImputer(strategy='most_frequent')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
X = df_imputed.drop(columns=['DATE_DIED', 'CLASIFFICATION_FINAL'])
y = df_imputed['CLASIFFICATION_FINAL'].apply(lambda x: 1 if x < 4 else 0)  # 1: risco alto, 0: risco baixo
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Função para treinar e avaliar os modelos
def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{model_name}")
    print(classification_report(y_test, y_pred))

# Modelos que precisam de normalização
models_to_normalize = {
    "Support Vector Machine (padrão)": SVC(),
    "Support Vector Machine (kernel poli)": SVC(kernel='poly'),
    "KNN (padrão)": KNeighborsClassifier(),
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5),
    "KNN (métrica minkowski)": KNeighborsClassifier(metric='minkowski'),
    "Perceptron": Perceptron()
}

# Modelos que não precisam de normalização
models_no_normalize = {
    "Árvore de Decisão CART": DecisionTreeClassifier(),
    "Gaussian Naive Bayes (padrão)": GaussianNB(),
    "Linear Discriminant Analysis (LDA)": LinearDiscriminantAnalysis()
}

# Imputação dos dados
imputer = SimpleImputer(strategy='mean') # Imputação de valores faltantes
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Verificação de NaNs após imputação
print("Verificação de NaNs após imputação:")
print("Valores faltantes em X_train_imputed:", pd.isnull(X_train_imputed).sum().sum())
print("Valores faltantes em X_test_imputed:", pd.isnull(X_test_imputed).sum().sum())

# Normalização dos dados
scaler = StandardScaler()
X_train_normalized = scaler.fit_transform(X_train_imputed)
X_test_normalized = scaler.transform(X_test_imputed)

# Verificação de NaNs após normalização
print("Verificação de NaNs após normalização:")
print("Valores faltantes em X_train_normalized:", pd.isnull(X_train_normalized).sum().sum())
print("Valores faltantes em X_test_normalized:", pd.isnull(X_test_normalized).sum().sum())

# Função para treinar e avaliar os modelos
def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{model_name}")
    print(classification_report(y_test, y_pred))

"""# Árvore de Decisão CART (padrão)"""

# Imputação X_train__imputed e X_test_imputed
cart = DecisionTreeClassifier()
train_and_evaluate_model(cart, X_train_imputed, y_train, X_test_imputed, y_test, "Árvore de Decisão CART")

"""# Support Vector Machine (padrão)"""

svm = SVC()
train_and_evaluate_model(svm, X_train_normalized, y_train, X_test_normalized, y_test, "Support Vector Machine (padrão)")

"""# Support Vector Machine (mudando o kernel por outro)"""

svm_poly = SVC(kernel='poly')
train_and_evaluate_model(svm_poly, X_train, y_train, X_test, y_test, "Support Vector Machine (kernel poli)")

"""# KNN (padrão)"""

knn = KNeighborsClassifier()
train_and_evaluate_model(knn, X_train, y_train, X_test, y_test, "KNN (padrão)")

"""# KNN (mudando o valor de k)"""

knn_k5 = KNeighborsClassifier(n_neighbors=5)
train_and_evaluate_model(knn_k5, X_train, y_train, X_test, y_test, "KNN (k=5)")

"""# KNN (mudando a medida de distância)"""

knn_minkowski = KNeighborsClassifier(metric='minkowski')
train_and_evaluate_model(knn_minkowski, X_train, y_train, X_test, y_test, "KNN (métrica minkowski)")

"""# Gaussian Naive Bayes (padrão)"""

gnb = GaussianNB()
train_and_evaluate_model(gnb, X_train, y_train, X_test, y_test, "Gaussian Naive Bayes (padrão)")

"""# Categorical Naive Bayes (padrão), considerando todos os atributos categóricos"""

cat_nb = CategoricalNB()
train_and_evaluate_model(cat_nb, X_train_cat, y_train_cat, X_test_cat, y_test_cat, "Categorical Naive Bayes (padrão)")

"""# 1.9 Regressão Linear (quadrados mínimos), regressão Linear não é adequada para classificação binária, então usamos LinearDiscriminantAnalysis"""

lda = LinearDiscriminantAnalysis()
train_and_evaluate_model(lda, X_train, y_train, X_test, y_test, "Linear Discriminant Analysis (LDA)")

"""# Perceptron"""

perceptron = Perceptron()
train_and_evaluate_model(perceptron, X_train, y_train, X_test, y_test, "Perceptron")